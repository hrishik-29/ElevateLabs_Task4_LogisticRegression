# ElevateLabs_Task4_LogisticRegression
# Task 4: Classification with Logistic Regression - AI & ML Internship

## Objective
The objective of this task was to build a binary classifier using Logistic Regression. This involved hands-on experience with data preprocessing, model training, evaluation using specific classification metrics, and understanding key concepts like the sigmoid function.

## Tools Used
* **Scikit-learn:** For implementing Logistic Regression, data splitting, feature scaling, and evaluation metrics.
* **Pandas:** For data loading and manipulation.
* **Matplotlib:** For data visualization, especially plotting the ROC curve.
* **NumPy:** Implicitly used by Pandas and Scikit-learn, often explicitly imported for numerical operations.

## Dataset
The dataset used for this task was the **Breast Cancer Wisconsin Dataset**. This dataset is commonly used for binary classification tasks, aiming to predict whether a tumor is malignant or benign based on various features.

## Steps Performed

1.  **Data Loading and Initial Exploration:**
    * The Breast Cancer Wisconsin Dataset was loaded (either from a CSV or using Scikit-learn's built-in dataset loader).
    * Features and the target variable (indicating malignancy/benignancy) were separated into `X` and `y` respectively.

2.  **Data Splitting and Feature Standardization:**
    * The dataset was split into training and testing sets using `train_test_split`, ensuring stratification to maintain class proportions.
    * Features were standardized using `StandardScaler` to bring them to a common scale, which helps the Logistic Regression model converge efficiently and perform better.

3.  **Model Training (Logistic Regression):**
    * A `LogisticRegression` model from `sklearn.linear_model` was initialized and trained on the scaled training data (`X_train_scaled`, `y_train`).

4.  **Model Evaluation:**
    * Predictions (`y_pred`) were made on the scaled test set (`X_test_scaled`).
    * The model's performance was rigorously evaluated using the following classification-specific metrics:
        * **Confusion Matrix:** A table that describes the performance of a classification model on a set of test data for which the true values are known. It shows the counts of true positives, true negatives, false positives, and false negatives.
        * **Precision:** The ratio of correctly predicted positive observations to the total predicted positives. It measures the quality of a positive prediction.
        * **Recall (Sensitivity):** The ratio of correctly predicted positive observations to all observations in the actual class. It measures the ability of the model to find all positive samples.
        * **F1-Score:** The weighted average of Precision and Recall. It is useful when you need to seek a balance between Precision and Recall.
        * **ROC-AUC Score (Receiver Operating Characteristic - Area Under the Curve):** A performance measurement for classification problems at various threshold settings. AUC represents the degree or measure of separability between classes. A higher AUC means the model is better at distinguishing between positive and negative classes.

5.  **Visualization (ROC Curve):**
    * An ROC curve was plotted to visualize the model's performance across different classification thresholds. This plot shows the trade-off between the True Positive Rate (Sensitivity) and the False Positive Rate. The area under this curve (ROC-AUC score) provides a single metric for overall model performance.

## What I Learned
* Gained practical experience in implementing a binary classifier using Logistic Regression.
* Understood the importance of data preprocessing steps unique to classification, such as feature scaling.
* Learned how to split data effectively for training and testing, including stratification for imbalanced datasets.
* Deepened understanding of key classification evaluation metrics (Confusion Matrix, Precision, Recall, F1-Score, ROC-AUC) and their interpretation.
* Practiced visualizing classifier performance through the ROC curve.
* Reinforced knowledge about the sigmoid function and its role in transforming linear outputs into probabilities for classification.
